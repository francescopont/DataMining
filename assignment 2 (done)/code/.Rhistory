ntree = optimal.ntree, type = "classification")
# Predicting the Test set results
random.forests.predictions <- predict(classifier, newdata = test.dtm)
print(table(random.forests.predictions,test.labels))
library(tm)
library(entropy)
library(SnowballC)
library(rpart)
library(rpart.plot)
#training set
training.dtm <- cleaning.function(training.corpus.dec,training.corpus.true)
#extraction of unigrams
training.dtm.unigrams <- DocumentTermMatrix(training.dtm)
training.dtm.unigrams <- removeSparseTerms(training.dtm.unigrams,0.95)
training.dtm.unigrams <- as.matrix(training.dtm.unigrams)
#extraction of bigrams
BigramTokenizer <-function(x) unlist(lapply(ngrams(words(x), 2), paste, collapse = " "), use.names = FALSE)
training.dtm.bigrams <- DocumentTermMatrix(training.dtm,control = list(tokenize = BigramTokenizer))
training.dtm.bigrams <- removeSparseTerms(training.dtm.bigrams,0.95)
training.dtm.bigrams <- as.matrix(training.dtm.bigrams)
#training set with both unigrams and bigrams
training.labels <- c(rep(0,320),rep(1,320))
training.dtm <- cbind(training.dtm.unigrams, training.dtm.bigrams)
###################################################################################
#test set
test.dtm <- cleaning.function (testing.corpus.dec,testing.corpus.true)
#unigrams
test.dtm.unigrams<- DocumentTermMatrix(test.dtm,list(dictionary=dimnames(training.dtm.unigrams)[[2]]))
test.dtm.unigrams <- as.matrix(test.dtm.unigrams)
#bigrams
test.dtm.bigrams<- DocumentTermMatrix(test.dtm,list(dictionary=dimnames(training.dtm.bigrams)[[2]]))
test.dtm.bigrams <- as.matrix(test.dtm.bigrams)
#test set with both unigrams and bigrams
test.labels <- c(rep(0,80),rep(1,80))
test.dtm <- cbind(test.dtm.unigrams, test.dtm.bigrams)
#######################################################
# grow the tree with only unigrams
reviews.rpart.unigrams <- rpart(label~.,
data=data.frame(training.dtm.unigrams,label = training.labels),
cp=0,method="class", minbucket = 1, minsplit = 2 )
# tree with lowest cv error
opt.cp.unigrams <-  reviews.rpart.unigrams$cptable[which.min(reviews.rpart.unigrams$cptable[,"xerror"]),"CP"]
print(opt.cp.unigrams)
plotcp(reviews.rpart.unigrams)
printcp(reviews.rpart.unigrams)
reviews.rpart.unigrams.pruned <- prune(reviews.rpart.unigrams,cp = reviews.rpart.unigrams$cptable[which.min(reviews.rpart.unigrams$cptable[,"xerror"]),"CP"] )
rpart.plot(reviews.rpart.unigrams.pruned, roundint = FALSE)
# make predictions on the test set
reviews.rpart.unigrams.pred <- predict(reviews.rpart.unigrams.pruned,
newdata=data.frame(as.matrix(test.dtm.unigrams)),type="class")
# show confusion matrix
print(table(reviews.rpart.unigrams.pred,test.labels))
#######################################################################################
#unigrams and bigrams
reviews.rpart <- rpart(label~.,
data=data.frame(training.dtm,label = training.labels),
cp=0,method="class", minbucket = 1, minsplit = 2)
# tree with lowest cv error
opt.cp <-  reviews.rpart$cptable[which.min(reviews.rpart$cptable[,"xerror"]),"CP"]
print(opt.cp)
plotcp(reviews.rpart)
printcp(reviews.rpart)
reviews.rpart.pruned <- prune(reviews.rpart,cp = reviews.rpart$cptable[which.min(reviews.rpart$cptable[,"xerror"]),"CP"] )
rpart.plot(reviews.rpart.unigrams.pruned, roundint = FALSE)
# make predictions on the test set
reviews.rpart.pred <- predict(reviews.rpart.pruned,
newdata=data.frame(as.matrix(test.dtm)),type="class")
# show confusion matrix
print(table(reviews.rpart.pred,test.labels))
library("glmnet")
#training set
training.dtm <- cleaning.function(training.corpus.dec,training.corpus.true)
#extraction of unigrams
training.dtm.unigrams <- DocumentTermMatrix(training.dtm)
training.dtm.unigrams <- removeSparseTerms(training.dtm.unigrams,0.95)
training.dtm.unigrams <- as.matrix(training.dtm.unigrams)
#extraction of bigrams
BigramTokenizer <-function(x) unlist(lapply(ngrams(words(x), 2), paste, collapse = " "), use.names = FALSE)
training.dtm.bigrams <- DocumentTermMatrix(training.dtm,control = list(tokenize = BigramTokenizer))
training.dtm.bigrams <- removeSparseTerms(training.dtm.bigrams,0.95)
training.dtm.bigrams <- as.matrix(training.dtm.bigrams)
#training set with both unigrams and bigrams
training.labels <- c(rep(0,320),rep(1,320))
training.dtm <- cbind(training.dtm.unigrams, training.dtm.bigrams)
#test set
test.dtm <- cleaning.function (testing.corpus.dec,testing.corpus.true)
#unigrams
test.dtm.unigrams<- DocumentTermMatrix(test.dtm,list(dictionary=dimnames(training.dtm.unigrams)[[2]]))
test.dtm.unigrams <- as.matrix(test.dtm.unigrams)
#bigrams
test.dtm.bigrams<- DocumentTermMatrix(test.dtm,list(dictionary=dimnames(training.dtm.bigrams)[[2]]))
test.dtm.bigrams <- as.matrix(test.dtm.bigrams)
#test set with both unigrams and bigrams
test.labels <- c(rep(0,80),rep(1,80))
test.dtm <- cbind(test.dtm.unigrams, test.dtm.bigrams)
####################################################################
#first model (only unigrams)
reviews.glmnet.unigrams <- cv.glmnet(training.dtm.unigrams,training.labels,
family="binomial",type.measure="class")
print(coef(reviews.glmnet.unigrams,s="lambda.min"))
print(reviews.glmnet.unigrams$lambda.min)
plot (reviews.glmnet.unigrams)
reviews.logreg.pred.unigrams <- predict(reviews.glmnet.unigrams,
newx=test.dtm.unigrams,s="lambda.min",type="class")
print(table(reviews.logreg.pred.unigrams,test.labels))
#second model ( with bigrams)
reviews.glmnet <- cv.glmnet(training.dtm,training.labels,
family="binomial",type.measure="class")
print(coef(reviews.glmnet,s="lambda.min"))
print(reviews.glmnet$lambda.min)
plot(reviews.glmnet)
reviews.logreg.pred <- predict(reviews.glmnet,
newx=test.dtm,s="lambda.min",type="class")
print(table(reviews.logreg.pred.unigrams,test.labels))
source('~/GitHub/DataMining/assignment 2/code/Naive Bayes.R')
library(entropy)
#training set
training.dtm <- cleaning.function(training.corpus.dec,training.corpus.true)
#extraction of unigrams
training.dtm.unigrams <- DocumentTermMatrix(training.dtm)
training.dtm.unigrams <- removeSparseTerms(training.dtm.unigrams,0.95)
training.dtm.unigrams <- as.matrix(training.dtm.unigrams)
#extraction of bigrams
BigramTokenizer <-function(x) unlist(lapply(ngrams(words(x), 2), paste, collapse = " "), use.names = FALSE)
training.dtm.bigrams <- DocumentTermMatrix(training.dtm,control = list(tokenize = BigramTokenizer))
training.dtm.bigrams <- removeSparseTerms(training.dtm.bigrams,0.95)
training.dtm.bigrams <- as.matrix(training.dtm.bigrams)
#training set with both unigrams and bigrams
training.labels <- c(rep(0,320),rep(1,320))
training.dtm <- cbind(training.dtm.unigrams, training.dtm.bigrams)
###################################################################################
#test set
test.dtm <- cleaning.function (testing.corpus.dec,testing.corpus.true)
#unigrams
test.dtm.unigrams<- DocumentTermMatrix(test.dtm,list(dictionary=dimnames(training.dtm.unigrams)[[2]]))
test.dtm.unigrams <- as.matrix(test.dtm.unigrams)
#bigrams
test.dtm.bigrams<- DocumentTermMatrix(test.dtm,list(dictionary=dimnames(training.dtm.bigrams)[[2]]))
test.dtm.bigrams <- as.matrix(test.dtm.bigrams)
#test set with both unigrams and bigrams
test.labels <- c(rep(0,80),rep(1,80))
test.dtm <- cbind(test.dtm.unigrams, test.dtm.bigrams)
########################################################################################
#feature selection (with mutual information, only for unigrams)
training.dtm.unigrams.mi <- apply(training.dtm.unigrams,2,function(x,y){
mi.plugin(table(x,y)/length(y))},training.labels)
training.dtm.unigrams.mi.order <- order(training.dtm.unigrams.mi,decreasing = T)
#feature selection ( with mutual information)
training.dtm.mi <- apply(training.dtm,2,function(x,y){
mi.plugin(table(x,y)/length(y))},training.labels)
training.dtm.mi.order <- order(training.dtm.mi,decreasing = T)
###########################################################################################
#print
print(dim(training.dtm.bigrams))
print(dim(training.dtm.unigrams))
print(colnames(training.dtm.bigrams))
print(dim(training.dtm)) ## just to check
print(training.dtm.mi[training.dtm.mi.order[1:10]])
#first model ( with feature selection according to mutual information)(only unigrams)
accuracies.unigrams.mi.models <- sapply(c(2:307), function (num.features){
model.mi <-train.mnb(training.dtm.unigrams[,training.dtm.unigrams.mi.order[1:num.features] ], training.labels)
predictions.mi <- predict.mnb(model.mi , test.dtm.unigrams[,training.dtm.unigrams.mi.order[1:num.features]])
conf.mat <- table (predictions.mi ,test.labels)
return (sum(diag(conf.mat))/180)
} )
accuracies.unigrams.mat <- cbind (accuracies.unigrams.mi.models, c(2:307))
accuracies.unigrams.best.n <- accuracies.unigrams.mat[which.max(accuracies.unigrams.mat[,1]), 2]
print(accuracies.unigrams.mat)
print(accuracies.unigrams.best.n)
plot(accuracies.unigrams.mat[,2] ,accuracies.unigrams.mat[,1], xlab = "n", ylab = "accuracy", type = "l")
model.unigrams.mi <-train.mnb(training.dtm.unigrams[,training.dtm.unigrams.mi.order[1:accuracies.unigrams.best.n] ], training.labels)
naive.bayes.predictions.unigrams.mi <- predict.mnb(model.unigrams.mi , test.dtm.unigrams[,training.dtm.unigrams.mi.order[1:accuracies.unigrams.best.n]])
print(table (naive.bayes.predictions.unigrams.mi ,test.labels))
#second model ( with feature selection according to mutual information)(both unigrams and bigrams)
accuracies.mi.models <- sapply(c(2:319), function (num.features){
model.mi <-train.mnb(training.dtm[,training.dtm.mi.order[1:num.features] ], training.labels)
predictions.mi <- predict.mnb(model.mi , test.dtm[,training.dtm.mi.order[1:num.features]])
conf.mat <- table (predictions.mi ,test.labels)
return (sum(diag(conf.mat))/180)
} )
accuracies.mat <- cbind (accuracies.mi.models, c(2:319))
accuracies.best <- accuracies.mat[which.max(accuracies.mat[,1]), 2]
print(accuracies.mat)
print(accuracies.best)
plot(accuracies.mat[,2] ,accuracies.mat[,1], xlab = "n", ylab = "accuracy", type = "l")
model.mi <-train.mnb(training.dtm[,training.dtm.mi.order[1:accuracies.best] ], training.labels)
naive.bayes.predictions.mi <- predict.mnb(model.mi , test.dtm[,training.dtm.mi.order[1:accuracies.best]])
print(table (naive.bayes.predictions.mi ,test.labels))
#training set
training.dtm <- cleaning.function(training.corpus.dec,training.corpus.true)
#extraction of unigrams
training.dtm.unigrams <- DocumentTermMatrix(training.dtm)
training.dtm.unigrams <- removeSparseTerms(training.dtm.unigrams,0.95)
training.dtm.unigrams <- as.matrix(training.dtm.unigrams)
#extraction of bigrams
BigramTokenizer <-function(x) unlist(lapply(ngrams(words(x), 2), paste, collapse = " "), use.names = FALSE)
training.dtm.bigrams <- DocumentTermMatrix(training.dtm,control = list(tokenize = BigramTokenizer))
training.dtm.bigrams <- removeSparseTerms(training.dtm.bigrams,0.95)
training.dtm.bigrams <- as.matrix(training.dtm.bigrams)
#training set with both unigrams and bigrams
training.labels <- c(rep(0,320),rep(1,320))
training.dtm <- cbind(training.dtm.unigrams, training.dtm.bigrams)
###################################################################################
#test set
test.dtm <- cleaning.function (testing.corpus.dec,testing.corpus.true)
#unigrams
test.dtm.unigrams<- DocumentTermMatrix(test.dtm,list(dictionary=dimnames(training.dtm.unigrams)[[2]]))
test.dtm.unigrams <- as.matrix(test.dtm.unigrams)
#bigrams
test.dtm.bigrams<- DocumentTermMatrix(test.dtm,list(dictionary=dimnames(training.dtm.bigrams)[[2]]))
test.dtm.bigrams <- as.matrix(test.dtm.bigrams)
#test set with both unigrams and bigrams
test.labels <- c(rep(0,80),rep(1,80))
test.dtm <- cbind(test.dtm.unigrams, test.dtm.bigrams)
########################################################################################
#feature selection (with mutual information, only for unigrams)
training.dtm.unigrams.mi <- apply(training.dtm.unigrams,2,function(x,y){
mi.plugin(table(x,y)/length(y))},training.labels)
training.dtm.unigrams.mi.order <- order(training.dtm.unigrams.mi,decreasing = T)
#feature selection ( with mutual information)
training.dtm.mi <- apply(training.dtm,2,function(x,y){
mi.plugin(table(x,y)/length(y))},training.labels)
training.dtm.mi.order <- order(training.dtm.mi,decreasing = T)
###########################################################################################
#print
print(dim(training.dtm.bigrams))
print(dim(training.dtm.unigrams))
print(colnames(training.dtm.bigrams))
print(dim(training.dtm)) ## just to check
print(training.dtm.mi[training.dtm.mi.order[1:10]])
#first model ( with feature selection according to mutual information)(only unigrams)
accuracies.unigrams.mi.models <- sapply(c(2:307), function (num.features){
model.mi <-train.mnb(training.dtm.unigrams[,training.dtm.unigrams.mi.order[1:num.features] ], training.labels)
predictions.mi <- predict.mnb(model.mi , test.dtm.unigrams[,training.dtm.unigrams.mi.order[1:num.features]])
conf.mat <- table (predictions.mi ,test.labels)
return (sum(diag(conf.mat))/180)
} )
accuracies.unigrams.mat <- cbind (accuracies.unigrams.mi.models, c(2:307))
accuracies.unigrams.best.n <- accuracies.unigrams.mat[which.max(accuracies.unigrams.mat[,1]), 2]
print(accuracies.unigrams.mat)
print(accuracies.unigrams.best.n)
plot(accuracies.unigrams.mat[,2] ,accuracies.unigrams.mat[,1], xlab = "n", ylab = "accuracy", type = "l")
model.unigrams.mi <-train.mnb(training.dtm.unigrams[,training.dtm.unigrams.mi.order[1:accuracies.unigrams.best.n] ], training.labels)
print(model.unigrams.mi)
naive.bayes.predictions.unigrams.mi <- predict.mnb(model.unigrams.mi , test.dtm.unigrams[,training.dtm.unigrams.mi.order[1:accuracies.unigrams.best.n]])
print(table (naive.bayes.predictions.unigrams.mi ,test.labels))
#second model ( with feature selection according to mutual information)(both unigrams and bigrams)
accuracies.mi.models <- sapply(c(2:319), function (num.features){
model.mi <-train.mnb(training.dtm[,training.dtm.mi.order[1:num.features] ], training.labels)
predictions.mi <- predict.mnb(model.mi , test.dtm[,training.dtm.mi.order[1:num.features]])
conf.mat <- table (predictions.mi ,test.labels)
return (sum(diag(conf.mat))/180)
} )
accuracies.mat <- cbind (accuracies.mi.models, c(2:319))
accuracies.best <- accuracies.mat[which.max(accuracies.mat[,1]), 2]
print(accuracies.mat)
print(accuracies.best)
plot(accuracies.mat[,2] ,accuracies.mat[,1], xlab = "n", ylab = "accuracy", type = "l")
model.mi <-train.mnb(training.dtm[,training.dtm.mi.order[1:accuracies.best] ], training.labels)
print(model.mi)
naive.bayes.predictions.mi <- predict.mnb(model.mi , test.dtm[,training.dtm.mi.order[1:accuracies.best]])
print(table (naive.bayes.predictions.mi ,test.labels))
print(model.unigrams.mi)
cond.probabilities.unigrams <- model.unigrams.mi$cond.probs
cond.probabilities.unigrams
class(cond.probabilities.unigrams)
cond.probabilities.unigrams[,3] <- log(cond.probabilities.unigrams[,2], 10) - log(cond.probabilities.unigrams[,1],10)
for (  index in c(1:nrow(cond.probabilities.unigrams))){cond.probabilities.unigrams[i,3] = log(cond.probabilities.unigrams[i,2], 10) - log(cond.probabilities.unigrams[i,1],10) }
for (  i in c(1:nrow(cond.probabilities.unigrams))){cond.probabilities.unigrams[i,3] = log(cond.probabilities.unigrams[i,2], 10) - log(cond.probabilities.unigrams[i,1],10) }
difference.unigrams <- log(cond.probabilities.unigrams[,2], 10) - log(cond.probabilities.unigrams[,1],10)
cbind(cond.probabilities.unigrams, difference.unigrams)
cond.probabilities.unigrams[order(cond.probabilities.unigrams[,3]),]
cond.probabilities.unigrams[order(cond.probabilities.unigrams$difference.unigrams),]
cond.probabilities.unigrams[order(cond.probabilities.unigrams[,3]),]
cond.probabilities.unigrams[order(cond.probabilities.unigrams[,2]),]
cond.probabilities.unigrams <- model.unigrams.mi$cond.probs
cond.probabilities.unigrams <- cbind(cond.probabilities.unigrams, difference.unigrams)
cond.probabilities.unigrams
cond.probabilities.unigrams
cond.probabilities.unigrams[order(cond.probabilities.unigrams[,3]),]
cond.probabilities.unigrams[order(cond.probabilities.unigrams[,3], desc = TRUE), ]
cond.probabilities.unigrams[order(-cond.probabilities.unigrams[,3]), ]
cond.probabilities <- model.mi$cond.probs
difference <- log(cond.probabilities[,2], 10) - log(cond.probabilities[,1],10)
cond.probabilities <- cbind(cond.probabilities, difference)
cond.probabilities[order(-cond.probabilities[,3]), ]
reviews.logreg.pred.is.correct <- sapply(c(1:length(reviews.logreg.pred)),function(index){
if(reviews.logreg.pred[index] == test.labels[index]){
return (1)
}
else (return (0))
})
reviews.logreg.pred.unigrams.is.correct <- sapply(c(1:length(reviews.logreg.pred.unigrams)),function(index){
if(reviews.logreg.pred.unigrams[index] == test.labels[index]){
return (1)
}
else (return (0))
})
naive.bayes.predictions.is.correct <- sapply(c(1:length(naive.bayes.predictions)),function(index){
if(naive.bayes.predictions[index] == test.labels[index]){
return (1)
}
else (return (0))
})
naive.bayes.predictions.unigrams.is.correct <- sapply(c(1:length(naive.bayes.predictions.unigrams)),function(index){
if(naive.bayes.predictions.unigrams[index] == test.labels[index]){
return (1)
}
else (return (0))
})
random.forests.predictions.is.correct <- sapply(c(1:length(random.forests.predictions)),function(index){
if(random.forests.predictions[index] == test.labels[index]){
return (1)
}
else (return (0))
})
random.forests.predictions.unigrams.is.correct <- sapply(c(1:length(random.forests.predictions.unigrams)),function(index){
if(random.forests.predictions.unigrams[index] == test.labels[index]){
return (1)
}
else (return (0))
})
reviews.rpart.pred.is.correct <- sapply(c(1:length(reviews.rpart.pred)),function(index){
if(reviews.rpart.pred[index] == test.labels[index]){
return (1)
}
else (return (0))
})
reviews.rpart.unigrams.pred.is.correct <- sapply(c(1:length(reviews.rpart.unigrams.pred)),function(index){
if(reviews.rpart.unigrams.pred[index] == test.labels[index]){
return (1)
}
else (return (0))
})
naive.vs.logreg.conf.matrix <- table(naive.bayes.predictions.is.correct, reviews.logreg.pred.is.correct)
mcnemar.test(naive.vs.logreg.conf.matrix)
reviews.logreg.pred.is.correct <- sapply(c(1:length(reviews.logreg.pred)),function(index){
if(reviews.logreg.pred[index] == test.labels[index]){
return (1)
}
else (return (0))
})
reviews.logreg.pred.unigrams.is.correct <- sapply(c(1:length(reviews.logreg.pred.unigrams)),function(index){
if(reviews.logreg.pred.unigrams[index] == test.labels[index]){
return (1)
}
else (return (0))
})
naive.bayes.predictions.mi.is.correct <- sapply(c(1:length(naive.bayes.predictions.mi)),function(index){
if(naive.bayes.predictions.mi[index] == test.labels[index]){
return (1)
}
else (return (0))
})
naive.bayes.predictions.unigrams.mi.is.correct <- sapply(c(1:length(naive.bayes.predictions.unigrams.mi)),function(index){
if(naive.bayes.predictions.unigrams.mi[index] == test.labels[index]){
return (1)
}
else (return (0))
})
random.forests.predictions.is.correct <- sapply(c(1:length(random.forests.predictions)),function(index){
if(random.forests.predictions[index] == test.labels[index]){
return (1)
}
else (return (0))
})
random.forests.predictions.unigrams.is.correct <- sapply(c(1:length(random.forests.predictions.unigrams)),function(index){
if(random.forests.predictions.unigrams[index] == test.labels[index]){
return (1)
}
else (return (0))
})
reviews.rpart.pred.is.correct <- sapply(c(1:length(reviews.rpart.pred)),function(index){
if(reviews.rpart.pred[index] == test.labels[index]){
return (1)
}
else (return (0))
})
reviews.rpart.unigrams.pred.is.correct <- sapply(c(1:length(reviews.rpart.unigrams.pred)),function(index){
if(reviews.rpart.unigrams.pred[index] == test.labels[index]){
return (1)
}
else (return (0))
})
naive.vs.logreg.conf.matrix <- table(naive.bayes.predictions.is.correct, reviews.logreg.pred.is.correct)
mcnemar.test(naive.vs.logreg.conf.matrix)
svm.vs.nn.conf.matrix <- table(mnist.svm.pred.is.correct, NNPredictions.is.correct)
mcnemar.test(svm.vs.nn.conf.matrix)
reviews.logreg.pred.is.correct <- sapply(c(1:length(reviews.logreg.pred)),function(index){
if(reviews.logreg.pred[index] == test.labels[index]){
return (1)
}
else (return (0))
})
reviews.logreg.pred.unigrams.is.correct <- sapply(c(1:length(reviews.logreg.pred.unigrams)),function(index){
if(reviews.logreg.pred.unigrams[index] == test.labels[index]){
return (1)
}
else (return (0))
})
naive.bayes.predictions.mi.is.correct <- sapply(c(1:length(naive.bayes.predictions.mi)),function(index){
if(naive.bayes.predictions.mi[index] == test.labels[index]){
return (1)
}
else (return (0))
})
naive.bayes.predictions.unigrams.mi.is.correct <- sapply(c(1:length(naive.bayes.predictions.unigrams.mi)),function(index){
if(naive.bayes.predictions.unigrams.mi[index] == test.labels[index]){
return (1)
}
else (return (0))
})
random.forests.predictions.is.correct <- sapply(c(1:length(random.forests.predictions)),function(index){
if(random.forests.predictions[index] == test.labels[index]){
return (1)
}
else (return (0))
})
random.forests.predictions.unigrams.is.correct <- sapply(c(1:length(random.forests.predictions.unigrams)),function(index){
if(random.forests.predictions.unigrams[index] == test.labels[index]){
return (1)
}
else (return (0))
})
reviews.rpart.pred.is.correct <- sapply(c(1:length(reviews.rpart.pred)),function(index){
if(reviews.rpart.pred[index] == test.labels[index]){
return (1)
}
else (return (0))
})
reviews.rpart.unigrams.pred.is.correct <- sapply(c(1:length(reviews.rpart.unigrams.pred)),function(index){
if(reviews.rpart.unigrams.pred[index] == test.labels[index]){
return (1)
}
else (return (0))
})
naive.vs.logreg.conf.matrix <- table(naive.bayes.predictions.is.correct, reviews.logreg.pred.is.correct)
mcnemar.test(naive.vs.logreg.conf.matrix)
reviews.logreg.pred.is.correct <- sapply(c(1:length(reviews.logreg.pred)),function(index){
if(reviews.logreg.pred[index] == test.labels[index]){
return (1)
}
else (return (0))
})
reviews.logreg.pred.unigrams.is.correct <- sapply(c(1:length(reviews.logreg.pred.unigrams)),function(index){
if(reviews.logreg.pred.unigrams[index] == test.labels[index]){
return (1)
}
else (return (0))
})
naive.bayes.predictions.mi.is.correct <- sapply(c(1:length(naive.bayes.predictions.mi)),function(index){
if(naive.bayes.predictions.mi[index] == test.labels[index]){
return (1)
}
else (return (0))
})
naive.bayes.predictions.unigrams.mi.is.correct <- sapply(c(1:length(naive.bayes.predictions.unigrams.mi)),function(index){
if(naive.bayes.predictions.unigrams.mi[index] == test.labels[index]){
return (1)
}
else (return (0))
})
random.forests.predictions.is.correct <- sapply(c(1:length(random.forests.predictions)),function(index){
if(random.forests.predictions[index] == test.labels[index]){
return (1)
}
else (return (0))
})
random.forests.predictions.unigrams.is.correct <- sapply(c(1:length(random.forests.predictions.unigrams)),function(index){
if(random.forests.predictions.unigrams[index] == test.labels[index]){
return (1)
}
else (return (0))
})
reviews.rpart.pred.is.correct <- sapply(c(1:length(reviews.rpart.pred)),function(index){
if(reviews.rpart.pred[index] == test.labels[index]){
return (1)
}
else (return (0))
})
reviews.rpart.unigrams.pred.is.correct <- sapply(c(1:length(reviews.rpart.unigrams.pred)),function(index){
if(reviews.rpart.unigrams.pred[index] == test.labels[index]){
return (1)
}
else (return (0))
})
naive.vs.logreg.conf.matrix <- table(naive.bayes.predictions.mi.is.correct, reviews.logreg.pred.is.correct)
mcnemar.test(naive.vs.logreg.conf.matrix)
print(naive.vs.logreg.conf.matrix)
naive.vs.logreg.conf.matrix.unigrams <- table(naive.bayes.predictions.unigrams.mi.is.correct, reviews.logreg.unigrams.pred.is.correct)
mcnemar.test(naive.vs.logreg.conf.matrix.unigrams)
naive.vs.logreg.conf.matrix.unigrams <- table(naive.bayes.predictions.unigrams.mi.is.correct, reviews.logreg.pred.unigrams.is.correct)
mcnemar.test(naive.vs.logreg.conf.matrix.unigrams)
naive.vs.logreg.conf.matrix.unigrams
random.forests.conf.matrix <- table(random.forets.predictions.unigrams.is.correct, random.forets.predictions.is.correct)
mcnemar.test(random.forests.conf.matrix )
random.forests.conf.matrix <- table(random.forests.predictions.unigrams.is.correct, random.forests.predictions.is.correct)
mcnemar.test(random.forests.conf.matrix )
random.forests.conf.matrix
random.forests.conf.matrix <- table(random.forests.predictions.is.correct,random.forests.predictions.unigrams.is.correct)
mcnemar.test(random.forests.conf.matrix )
naive.vs.random.conf.matrix <- table(naive.bayes.predictions.mi.is.correct, random.forests.predictions.is.correct)
mcnemar.test(naive.vs.random.conf.matrix)
logreg.vs.random.conf.matrix <- table(reviews.logreg.pred.is.correct, random.forests.predictions.is.correct)
mcnemar.test(logreg.vs.random.conf.matrix)
logreg.conf.matrix <- table(reviews.logreg.pred.is.correct, reviews.logreg.unigrams.pred.is.correct)
mcnemar.test(rlogreg.conf.matrix )
logreg.conf.matrix <- table(reviews.logreg.pred.is.correct, reviews.logreg.pred.unigrams.is.correct)
mcnemar.test(rlogreg.conf.matrix )
logreg.conf.matrix <- table(reviews.logreg.pred.is.correct, reviews.logreg.pred.unigrams.is.correct)
mcnemar.test(logreg.conf.matrix )
source('~/GitHub/DataMining/assignment 2/code/all in one.R')
