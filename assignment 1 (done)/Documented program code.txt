#tree.grow
###parameters###
#x: data matrix containing attribute values of the training set
#y: vector of class labels (0 or 1)
#nmin: number of observations that a node must contain at least, for it to be allowed to be split (integer)
#minleaf: minimun number of observations required for a leaf node (integer)
#nfeat: number of features to consider for each split (integer)
###returns###
# a dataframe where each row represents a node of the tree
###semantics of the attributes of the dataframe###
#node.id : identifier of the node (int)
#class.0 : number of observations in the current node with class 0 (integer)
#class.1 : number of observations in the current node with class 1 (integer)
#observations: list of all the identifiers (integer) of the observations pertaining to the current node
#left.id: identifier of the left child (integer)
#right.id: identifier of the right child(integer)
#split.attribute : identifier (the number of the column in the dataset) of the split attribute on which the node is split (integer) (-1 if leaf node)
#split.value: value of the split attribute on which the node is split (integer)( -1 if leaf node)
#is. splittable: 1 if the node can be split, 0 otherwise (integer)
tree.grow <- function(x,y,nmin, minleaf,nfeat){
  #creation of the dataframe with the root node
  tree <- data.frame (1, length(y[y==0]), sum(y[y==1]),list(1),-1,-1,-1,-1,1)
  names(tree) <- c("node.id", "class.0", "class.1", "observations", "left.id", "right.id", "split.attribute", "split.value", "is.splittable")
  tree$observations <- list(c(1:length(y)))
  
  #add observations identifiers
  x<- cbind(x, c(1:nrow(x)))
  
  while (sum(tree$is.splittable) > 0){#while there are splittable nodes
    splittable.rows <- which(tree$is.splittable == 1)
    for(row in splittable.rows){
        i <- tree[row,]
        if (length(i$observations[[1]]) < nmin){#the node can't be splitten
          tree[tree$node.id == i$node.id,]$is.splittable <- 0
        }
        else{
          #computation of all the best splitpoints for each attribute
          #we may want to use not all the attributes for random forests
          #we select the right observations
          x.filter = x[as.vector(unlist(i$observations)),]
          y.filter = y[as.vector(unlist(i$observations))]
          attributes.numbers <- sample(1:(ncol(x.filter)-1), nfeat, replace=FALSE)
          splitpoints <- sapply(attributes.numbers, function(i){bestsplit(x.filter[,i],y.filter, minleaf)})
          splitpoints <- t(splitpoints)
          
          #introduce a new column to keep track of the attribute corresponding to each splitpoint
          splitpoints <- cbind(splitpoints,attributes.numbers)
          
          #select only valid splitpoints, filtering out NA
          rows = complete.cases(splitpoints)
          splitpoints <- splitpoints[rows, ]
          if (length(splitpoints) == 0){#there is no splitpoint which respects the minleaf condition
            tree[tree$node.id == i$node.id,]$is.splittable <- 0
          }
          else{
            if(is.vector(splitpoints)){#there is only one candidate splitpoint
              #select the attribute and the value on which splitting
              split.value <- splitpoints[ 1]
              split.attribute <- splitpoints[ 3]
            }
            else{# there are more than one candidate splitpoints
              #order the splitpoints by their quality
              splitpoints <- splitpoints[order(splitpoints[,2], decreasing = TRUE), ]
              #select the attribute and the value on which splitting
              split.value <- splitpoints[1 , 1]
              split.attribute <- splitpoints[1, 3]
            }
            
            #determine the  observations per each child
            left.obs <- x.filter[x.filter[,split.attribute] > split.value, ncol(x.filter)]
            right.obs <- x.filter[x.filter[,split.attribute] <= split.value, ncol(x.filter)]
        
            #determine the number of elements per each class per each child node
            left.obs.1 <- sum(y[left.obs])
            left.obs.0 <- length(left.obs) - left.obs.1
            right.obs.1 <- sum(y[right.obs])
            right.obs.0 <- length(right.obs) - right.obs.1
            
            #determine the ids of the two new nodes
            left.id <- max(tree$node.id) +1
            right.id <- left.id +1
            
            #create the new nodes
            left.child <- data.frame (left.id,left.obs.0,left.obs.1,-1,-1,-1,-1,-1,1)
            names(left.child) <- c("node.id", "class.0", "class.1", "observations", "left.id", "right.id", "split.attribute", "split.value", "is.splittable")
            left.child$observations <- list(left.obs)
            
            right.child <- data.frame (right.id,right.obs.0,right.obs.1,-1,-1,-1,-1,-1,1)
            names(right.child) <- c("node.id", "class.0", "class.1", "observations", "left.id", "right.id", "split.attribute", "split.value", "is.splittable")
            right.child$observations <- list(right.obs)
            
            #update the parent node and the tree 
            tree[tree$node.id == i$node.id,]$left.id <- left.id
            tree[tree$node.id == i$node.id,]$right.id <- right.id
            tree[tree$node.id == i$node.id,]$is.splittable <- 0
            tree[tree$node.id == i$node.id,]$split.attribute <- split.attribute
            tree[tree$node.id == i$node.id,]$split.value <- split.value
            tree <- rbind(tree, left.child)
            tree <- rbind(tree, right.child)
          }
        }
    }
  }
  return (tree)
}

#tree.classify
###parameters###
#x: data matrix containing the attribute values of the cases for which predictions are required
#tr: tree object used to classify the observations (a dataframe in this implementation)
###returns ###
#vector of predicted class labels for the cases in x ( 0 or 1)
tree.classify <- function(x, tr){
  class.labels <- apply(x,1, function(i){
    current.node <- tr[1, ]
    while(current.node$split.attribute != -1){# we go through the dataframe until we reach a leaf node
      if (i[current.node$split.attribute] > current.node$split.value){
        current.node <- tr[current.node$left.id, ]
      }
      else{
        current.node <- tr[current.node$right.id, ]
      }
    }
    #we return a value depending on the majority of the observations in that leaf node
    if (current.node$class.0 > current.node$class.1){# if there is a tie we return 1
      return (0) 
    } 
    else return (1)
  })

}

#tree.grow.bag
###parameters###
#x: data matrix containing attribute values of the training set
#y: vector of class labels (0 or 1)
#nmin: number of observations that a node must contain at least, for it to be allowed to be split (integer)
#minleaf: minimun number of observations required for a leaf node (integer)
#m: number of bootstrap samples to be drawn (integer)
###returns ###
#a list of dataframes where each dataframe represents a tree, and each row of a dataframe a node of the tree
tree.grow.bag <- function(x,y,nmin, minleaf,nfeat,m){
  list.trees <- list()
  #grow trees and put in a list
  list.trees <- lapply(c(1:m), function(i){
    bootstrap.samples <- sample(nrow(x), size=nrow(x), replace = TRUE)
    x.bootstrap = x[bootstrap.samples,]
    y.bootstrap = y[bootstrap.samples]
    tree <- tree.grow(x.bootstrap,y.bootstrap,nmin,minleaf,nfeat)
    return (tree)
  })
  return (list.trees)
}

#tree.classify.bag
###parameters###
#x: data matrix containing the attribute values of the observations for which predictions are required
#list.trees:  list of trees objects used to classify the observations
#returns###
#a vector of predicted class labels for the observations in x (0 or 1)
tree.classify.bag <- function(x, list.trees){
  #apply the classify function for each tree of the list
  #returns a matrix where each row  is a vector of class labels for an observation
  classification_matrix <- sapply(list.trees, function(tree){
    labels <- tree.classify(x, tree)
    return (labels)
  })
  
  #decide on the majority of results
  classification_vector <- apply(classification_matrix, 1, function(row){
    if (length(row[row == 0]) >= length(row[row == 1])){#in case of tie we return 0
      return (0)
    }
      else return (1)
    })
  return (classification_vector)
}

#impurity
###parameters###
#y: vector of binary elements 
###returns###
#the impurity of the vector
impurity <- function(y){
  if(length(y)== 0){
    return (0)
  }
  x <- sum(y)/ length(y)
  result <- x*(1-x)
}
#bestplit
###parameters###
# x: vector of values of the observations for an attribute
# y: vector of class labels ( 0 or 1)
# minleaf: minimum number of observations required for a leaf node after the split(integer)
###returns###
#a data matrix composed of two columns: 
#splitpoints (the first column) is the value of the best splitpoint
#quality(the second column) is the quality of the split (alias the reduction of the impurity that the split achieves)
#this function caculates the best splitpoint (if it exists) for an attribute and a given set of observations
bestsplit <- function(x,y,minleaf){
  #create a unique matrix and order it
  my_matrix <- cbind(x,y)[order(x,y),]
  splitpoints <- sapply(c(2:nrow(my_matrix)-1), function(i){
    if(my_matrix[i,1] != my_matrix[i+1,1]){
      return ((my_matrix[i,1]+ my_matrix[i+1,1])/2)
    }
    else {
      return (NA)
    }
  })
  
  splitpoints <- splitpoints[!is.na(splitpoints)]
  #discard splitpoints which do not satisfy the minleaf condition
  splitpoints <- sapply(splitpoints, function(i){
    if (length(x[x<=i]) < minleaf || length(x[x > i])< minleaf){
      return (NA)
    }
    else {
      return (i)
    }
  })
  
  splitpoints <- splitpoints[!is.na(splitpoints)]
  #if no splitpoint has been found, we return an empty matrix
  if (length(splitpoints)==0){
    empty.matrix <- matrix(nrow=1, ncol=2, byrow = FALSE, dimnames = list(c(),c("splitpoints", "quality")))
    return (empty.matrix)
  }
  
  #compute the impurities of the children nodes generated by each split
  impurities <- sapply(splitpoints, function(i) {
    less_mat <- my_matrix[which(my_matrix[,1] <=i), 2]
    great_mat <- my_matrix[which(my_matrix[,1] > i), 2]
    #"impurity" generated by  split
    length(less_mat)*impurity(less_mat)/length(y) + length(great_mat)*impurity(great_mat)/length(y)
  })
  
  #compute the quality of splits
  quality <- impurity(y) - impurities
  quality_matrix <- cbind(splitpoints, quality)
  #select the best split and return it (if it exists)
  quality_matrix <- quality_matrix[which.max(quality_matrix[,2]), ]
  if (quality_matrix[2] > 0){
    return (quality_matrix)
  }
  else {
    empty.matrix <- matrix(nrow=1, ncol=2, byrow = FALSE, dimnames = list(c(),c("splitpoints", "quality")))
    return (empty.matrix)
  }
}





